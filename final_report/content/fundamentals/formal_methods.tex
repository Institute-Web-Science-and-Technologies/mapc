One of the challenges for multi-agent systems is how to make sure that the agent will not behave unacceptable or undesirable? Agents may act in complex production environments, where failure of a single agent may cause serious losses. Formal methods had been used in computer science as a basis to solve correctness challenges. They represent agents as a high level abstractions in complex systems. Such representation can lead to simpler techniques for design and development.

There are two roles of formal methods in distributed artificial intelligence that are often referred to. Firstly, with respect to precise specifications they help in debugging specifications and in validation of system implementations. Abstracting from specific implementation leads to better understanding of the design of the system being developed. Secondly, in the long run formal methods help in developing a clearer understanding of problems and their solutions. \cite{Singh_99}

To formalize the concepts of multi-agent systems different types of logics are used, such as propositional, modal, temporal and dynamic logics. In the following several paragraphs these logics, their properties and introduced operators will be briefly discussed. Describing the details of interpretations and models of each individual logic is not the purpose of this report and is left out for further reading.

Propositional logic is the simplest one and serves as a fundament for logics discussed further in this section. It is used for representing factual information and in our case is most suitable to model the agent's environment. Formulas in this logic language consist of atomic propositions (known facts about the world) and truth-functional connectives: $\land,\lor,\neg,\rightarrow$ which denote "and" "or" "not" and "implies" respectively. \cite{Enderton_72}

Modal logic extends propositional logic by introducing two different modes of truth: possibility and necessity. In the study of agents, it is used to give
meaning to concepts such as belief and knowledge. Syntactically modal operators in modal logic languages are defined as $\Diamond$  for possibility and
$\Box$ for necessity. The semantics of modal logics is traditionally given in terms of sets of the so-called possible worlds. A world here can be interpreted as a possible state of affairs or sequence of states of affairs (history). Different worlds can be related via a binary accessibility relation, which tells us which worlds are are within the realm of possibility from the standpoint of a given world. In the sense of the accessibility relation a condition is assumed possible if it is true somewhere in the realm of possibility and it is assumed necessary if it is true everywhere in the realm of possibility. \cite{Saul_63}

Dynamic logic is also can be referred to as modal logic of action. It adds differen atomic actions to the logic language. In our case atomic actions may be represented as actions that agents can perform directly. This makes dynamic logic very flexible and useful for distributed artificial intelligence systems. Necessity and possibility operators of dynamic logic are based upon the kinds of actions available. \cite{Kozen_90}

Temporal logic is the logic of time. There are several variations of this logic such as:
\begin{itemize}
  \item Linear or Branching: single course of history or multiple courses of history.
  \item Discrete or Dense: discrete steps(like natural numbers) or always having intermediate steps (like real numbers).
  \item Moment-based or Period-based: atoms of time are points or intervals.
\end{itemize}
We will concentrate on discrete moment-based models with linear past, but consider both linear and branching futures.

Linear temporal logic introduces several important operators. $p\cup q$ is true at a moment $t$ on a path, if and only if $q$ holds at a future moment on
the given path and $p$ holds on all moments between $t$ and the selected occurrence of $q$. $Fp$ means that $p$ holds sometimes in the future on the given path. $Gp$ means that $p$ always holds in the future on the given path. $Xp$ means that $p$ holds in the next moment. $Pq$ means that $q$ held in a past moment. \cite{Singh_99}
%
\begin{figure}[h!]
\caption{An example branching structure of time. (source: \cite{Singh_99})}
\centering
\includegraphics[width=0.6\textwidth]{images/branching_logic.png}
\label{sci:for_branching_figure}
\end{figure}

Branching temporal and action logic is built on top of both dynamic and linear temporal logics and captures the essential properties of actions and time that are of value in specifying agents. It also adds several specific branching-time operators. $A$ denotes "in all paths at the present moment". The present moment here is the moment at which a given formula is evaluated. $E$ denotes "in some path at the present moment". The reality operator $R$ denotes "in the real path at the present moment". Figure \ref{sci:for_branching_figure} illustrates the example of branching time for two interacting agents.

For modeling intelligent agents quite often used BDI concept, which was described earlier in this report. BDI stands for three cognitive specifications of agents: beliefs, desires, intensions. To model logic of these specifications we will need to introduce several modal operators: $Bel$ for beliefs, $Des$ for desires, $Int$ for intensions and $K_h$ for know how. Considering these operators, for example, the mental state of an agent who desires to win the lottery and intends to buy a lottery ticket sometime, but does not believe that he will ever win can be represented by the following formula: $DesAFwin \land IntEFbuy \land \neg BelAFwin$. For simplification in future we will consider only those desires which are mutually consistent. Such desires are usually called goals.

It is important to note several important properties of intensions, which should be maintained by all agents\cite{Singh_92}:
\begin{enumerate}
  \item Satisfiability: $xIntp\rightarrow EFp$. This means that if $p$ is intended by $x$, then it occurs eventually on some path. Intension following this condition is assumed satisfiable.
  \item Temporal consistency: $(xIntp \land xIntq)\rightarrow xInt(Fp \land Fq)$. This requires that if an agent intends $p$ and intends $q$, then it  (implicitly) intends achieving them in some undetermined temporal order: $p$ before $q$, $q$ before $p$, or both simultaneously.
  \item Persistence does not entail success: $EG((xIntp) \land \neg p)$ is satisfiable. This is quite intuitive: just because an agent persists with an intention does not mean that it will succeed.
  \item Persist while succeeding. This constraint requires that agents desist from revising their intentions as long as they are able to proceed properly.
\end{enumerate}

The introduced above concepts may be used in each of two roles of formal methods introduced earlier. There are two mostly used reasoning techniques to decide agent's actions: theorem proving and model checking. The first one is more complex in terms of calculations, when the second one is more practical, but it requires additional inputs, though it does not prove to be a problem in several cases.

Considering the practical implementation, the architecture of abstract BDI-interpreter can be described as follows. The inputs to the system are called events, and are received via an event queue. Events can be external or internal for the system. Based on its current state and input events the system selects and executes options, corresponding to some plans. The interpreter continually performs the following: determines available options, deliberates to commit some options, updates its state and executes chosen atomic actions, after that it updates the event queue and eliminates the options which already achieved or no longer possible.
%
\begin{lstlisting}
BDI-Interpreter
initialize_state();
do
    options := option-generator(event-queue, B, G, I);
    selected-options := deliberate(options, B, G, I);
    update-intentions(selected-options, I);
    execute(I);
    get-new-external-events();
    drop-successful-attitudes(B, G, I);
    drop-impossible-attitudes(B, G, I);
until quit.
\end{lstlisting}

As was mentioned above options are usually represented by plans. Plans consist of of the name or type, the body usually specified by a plan graph, invocation condition (triggering event), precondition specifying when it may be selected and add list with delete list, specifying which atomic propositions to be believed after successful plan execution. Intentions in this case may be represented as hierarchically related plans.

Getting back to the algorithm and assuming plans as options, the option generator may look like the following.
Given a set of trigger events from the event queue, the option generator iterates through the plan library and returns those plans whose invocation condition
matches the trigger event and whose preconditions are believed by the agent.
%
\begin{lstlisting}[mathescape]
option-generator(trigger-events, B, G ,I)
options := {};
for trigger-event $\in$ trigger-events do
    for plan $\in$ plan-library do
        if matches(invocation(plan, trigger-event) then
            if provable(precondition(plan), B) then
                options := options $\cup$ plan;
return options.
\end{lstlisting}

Deliberation of options should conform with the execution time constraints, therefor under certain circumstances random choice might be appropriate. Sometimes lengthy deliberation becomes possible by introducing metalevel plans into plan library, which form intentions towards some particular plans.
%
\begin{lstlisting}[mathescape]
deliberate(options)
if length(options) $\leq$ 1 then return options;
else metalevel-options :=
            option-generator(b-add(option-set(options)));
    selected-options := deliberate(metalevel-options);
    if null(selected-options) then
        return random-choice(options);
    else return selected-options.
\end{lstlisting}

Coordination is one of the core functionalities needed by multiagent systems. Especially when different agents autonomous and have different roles and possible actions.

One of the approaches developed by Singh \cite{Singh_97} represents each agent as a small skeleton, which includes only the events or
transitions made by the agent that are significant for coordination. The core of the architecture is the idea that agents should have limited knowledge about designs of other agents. This limited knowledge is called a significant events of the agent. Events can be of the four main types:
\begin{itemize}
  \item flexible, which can be delayed or omitted,
  \item inevitable, which can be only delayed,
  \item immediate, which agent willing to perform immediately,
  \item triggerable, which the agent performs based on external events.
\end{itemize}
These events are organized into skeletons that characterize the coordination behavior of agents. The coordination service is independent of the exact skeletons or events used by agents in a multiagent system.

To specify coordinations a variant of linear-time temporal language with some restrictions is used. For that purpose two temporal operators are introduced: $\cdot$ - before operator, and $\bigodot$ - the operator of concatenation of two time traces, first of which is finite. Such special logic allows a variety of different relationships to be captured. 

Overall, formal methods provide a logic abstraction for multiagent systems. They help to find self-consistent models of agent's behavior. However relatively high complexity do not allow these methods to be implemented in real time systems. Therefore the role of formal methods nowadays is limited to debug, validate and design purposes.

In our project we unfortunately did not apply any formal methods for debugging or validating, mostly because of the limited time for development.